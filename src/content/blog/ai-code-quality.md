---
title: "AIが生成したコードは安全か？品質管理の重要性"
date: "2026-01-07"
excerpt: "GitHub CopilotやChatGPTで生成したコードには品質リスクがあります。調査データを基に、AIコードの問題点と適切な品質管理の方法を解説します。"
author: "YDシステム"
tags: ["AIコード", "品質管理", "セキュリティ"]
category: "技術解説"
published: true
---

## AIコードの品質問題

GitHub CopilotやChatGPTを使ったコード生成が普及していますが、生成されたコードをそのまま使うのは危険です。

CSETの調査によると、**AIが生成したコードの約48%で何らかのバグが見つかり**、完全に安全だと検証されたコードは**全体のわずか約30%**でした。

## 具体的なリスク

### 1. セキュリティ脆弱性

Veracode社の調査では、AIが生成したコードサンプルの**45%がOWASP Top 10に含まれる重大な脆弱性**を含んでいました。

**よく見られる問題:**
- SQLインジェクション
- クロスサイトスクリプティング（XSS）
- 不適切な認証処理
- 入力値検証の欠如

特にJavaで生成されたコードは防御失敗率が72%と高く、XSS関連コードの86%で防御に失敗しています。

### 2. JWTの検証不備

実際に確認された例として、JWTの署名検証を実装していないコードが生成されることがあります。これでは改ざんされたトークンを検知できません。

### 3. 古いライブラリの使用

AIは外部ライブラリの使用を推奨することがありますが、それらが最新かつ安全である保証はありません。メンテナンスされていないライブラリを使用すると、セキュリティリスクが増大します。

## なぜ開発者は見落とすのか

ある調査では、**76%の開発者が「AIのコードは人間より安全だ」と考えている**ことがわかりました。

この過信が、危険な脆弱性を見過ごす原因になっています。

AIは：
- セキュリティの専門知識を完全には理解していない
- 学習データに含まれる脆弱性をそのまま出力することがある
- 文脈を完全に理解せず、不適切なコードを生成することがある

## 適切な品質管理の方法

![品質管理のポイント](/images/blog/chatbot-success-factors-infographic.png)

### 1. 人間によるコードレビュー

AIが生成したコードは、必ず人間がレビューします。

**レビューの観点:**
- セキュリティ脆弱性はないか
- エラーハンドリングは適切か
- パフォーマンスに問題はないか
- 可読性・保守性は確保されているか

### 2. 自動テストの活用

SAST（静的アプリケーションセキュリティテスト）やDAST（動的アプリケーションセキュリティテスト）を組み合わせることで、目視では見逃しやすい問題も検出できます。

### 3. 仕様ドキュメントの事前作成

開発着手前に仕様ドキュメントを作成し、エンジニアがレビューするフローを導入します。これにより、設計段階で問題点を洗い出せます。

### 4. AIへの前提条件の指示

AIに対して事前に以下を伝えることで、出力の質を安定させられます：

- 技術要件
- セキュリティ要件
- 使用してよいライブラリ
- コーディング規約

「新しいライブラリはなるべく使用しない」「枯れたライブラリだけを使う」といった指示も有効です。

### 5. PRの細分化

機能単位でPRを細かく分割し、レビューの負担を軽減します。大量のコードを一度にレビューすると、見落としが発生しやすくなります。

## YDシステムでの取り組み

当社では、AI生成コードに対して以下の品質管理を実施しています：

1. **AIによる一次チェック** + **人間による二次レビュー**
2. **自動テスト**（単体テスト・セキュリティテスト）
3. **コーディング規約の徹底**
4. **定期的なセキュリティ監査**

AIの生産性向上効果を享受しながら、品質は妥協しない体制を構築しています。

## まとめ

AIコード生成は便利なツールですが、「生成したら終わり」ではありません。

**AIは補助ツール、最終責任は人間が持つ**という姿勢で、適切な品質管理を行うことが重要です。

品質管理体制についてのご相談は、[お問い合わせページ](/contact)からお気軽にどうぞ。
